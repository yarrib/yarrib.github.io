[
  {
    "objectID": "posts/what-an-ms-in-ds-gets-you/index.html",
    "href": "posts/what-an-ms-in-ds-gets-you/index.html",
    "title": "What an MS in Data Science gets you",
    "section": "",
    "text": "I started thinking about additional education a few years after my undergrad. I played college golf, then tried to play professional golf, with a serious lack of success. After a few years, and the end of 2017 I decided that I was going to stop playing golf tournaments preofessionally and focus a little bit more on a career. I learned the basics of Python, PowerBI, and picked up some ancillary tools and skills. It took a little bit, but by early 2019 I was considering an MBA or a Master’s in Data Sience.\nInterestingly, I recieved more pro-MBA advice than those on the analytics side. Despite that I decided to pursue the MS in Data Science through an online program with the University of Wisconsin. Two primary factors motivated this decision, (1) the reasonable expense, and (2) that I could continue working while pursuing this degree. One hesitation with some in person and hybrid programs was giving up a stable income in order to take this step. Though some might see this as indecision, it was a form of hedging my bets; furthering my career prospects while continuing to work.\nFortunately, I was able to apply a lot of new skills to my existing job, whether self-taught or learned through my MS-DS program. And whats more is that via some networking within my program I was able to move into my current role. Yet after taking 2.5 years to complete an MS in Data Science I felt like a complete novice. This was in early 2022.\n\n\nWell, turns out that in a technical field getting a degree is only a small step in career progression. My bachelor’s degree was in business, and I do not have the STEM background that so many seem to have. That also means I’m not comfortable with math formulae, theorems, reading academic journals, or other pursuits. I missed out on the ins and outs of data structures, algorithms, and whatever else is taught in CS undergrad programs. However, I do have some less technical skills in communication, common sense, and business acumen.\nSo unlike the brilliant folks who have been technical since day 1, I moved into a techincal space at a later age. What my MS in Data Science has afforded me is a new space in which to learn, to take on new challenges, and bridge the gap between technical and non-technical folks. More experienced techincal practictioners have to learn the business side eventually. My path is reversed. I think there are others like me, others that are getting excited about technical fields later in life. Whether it is data science or another field, the point is that an MS or other degree is a stepping stone. It’s a path forward that can get you started and give you that kick forward that many of us need.\n\n\n\nAn MS in Data Science gets you moving forward, might get you a job, but more importantly gets you some notion as to whether you are ready to commit to continous learning. There are a lot of paths forward in the domain of data science, from BI to AI. No, despite what people say not everything is going to be automated tomorrow.\nI am moving forward with much to learn, but a solid base from which to find a specialty. Presently I am engaged in work and education in the areas of MLOps, cloud infrastructure, and deep learning. Like many I feel overwhelmed with the infinite space of things that one could learn. And I am guilty of paralysis by analysis, specifically making lists of what to do learn next with a course or book, instead of learning by doing and figuring out the details as I go. I’m attepting to do the latter, and I encourage anyone to do the same. It seems far more productive.\nAs a parting thought, don’t be too hard on yourself. If you are like me and find your free time taken up by real life, don’t sweat it. Some practice where you can spare it is better than none. And spending time on recreation, fitness, and kids (if you have them) is probably far more important than trying to keep up on the latest development in AI."
  },
  {
    "objectID": "posts/my-foray-into-blogging/index.html",
    "href": "posts/my-foray-into-blogging/index.html",
    "title": "Why would I blog?",
    "section": "",
    "text": "Why would I blog?\n\nPlus some bonus Python coding\n\n\nPhoto by Ameen Fahmy on Unsplash\nThe main reason I’m starting this blog is because I’ve been hesitant to do so. I prefer not to share too much information, so this is a sort of personal challenge. Also, Jeremy and Rachel over at FastAI are adament about blogging as a means of learning deep learning (or any topic for that matter). I agree with this perspective despite maintaining that the idea of blogging is better than actually doing it. I’ll keep tabs on this perspective over time.\nI’m going to do things a little differently, in my own style, and will probably break a bunch of blogging guidelines. I’m going to be mixing thoughts and ideas with data science code snippets and projects. While I have some ideas for upcoming posts I also am likely to interject random tutorials which I would consider things that are useful to me.\nThe goal of this isn’t to make money or anything like that. It is simply to get comfortable being uncomfortable in posting content and sharing thoughts, ideas and projects. The personal gain I am seeking will be the product of committing to the habit and practicing it.\nSo with that, lets go through a little python code that I find to be indespensible: comprehensions. I find myself interjecting list and dictionary comprehensions in all manner of code I write in Python. For instance, if I need to: filter some data based on a condition, manipulate dictionary keys and values, or update Pandas Dataframe column names. I’ll show those examples below, in contrast with some other methods.\n\n\nComprehensions\nPerform calculations on a list\nFirst we need a list to work with, which is easy enough to create in python:\n\nlist_1 = list(range(25))\nprint(list_1)\n\n[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]\n\n\nOk, so we have a list. Lets find the odd numbers using loops:\n\nodd_nums = []\nfor item in list_1:\n    if item%2 != 0:\n        odd_nums.append(item)\nprint(odd_nums)\n\n[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]\n\n\nWell that works, but kind of long winded. A list comp can shorten it up for us:\n\nodd_nums_lc = [item for item in list_1 if item%2 != 0]\nprint(odd_nums_lc)\n\n[1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23]\n\n\nSimilar methods also work for nested lists. It should be noted however, that comprehensions can be harder to read, so extensively nested statements might be best being split up or incorporating some sort of loop or helper function.\nGetting some corpus - body of text - into a dictionary of word counts\nWell we need a dict, so lets take some text and do a word count. We will use the first 2 paragraphs from the Wikipedia entry for Gandalf\n\ngandalf = \"\"\"\nGandalf is a protagonist in J. R. R. Tolkien's novels The Hobbit and The Lord of the Rings. \nHe is a wizard, one of the Istari order, and the leader of the Fellowship of the Ring. Tolkien took the \nname \"Gandalf\" from the Old Norse \"Catalogue of Dwarves\" (Dvergatal) in the Völuspá.\n\nAs a wizard and the bearer of one of the Three Rings, Gandalf has great power, but works mostly by \nencouraging and persuading. He sets out as Gandalf the Grey, possessing great knowledge and \ntravelling continually. Gandalf is focused on the mission to counter the Dark Lord Sauron by \ndestroying the One Ring. He is associated with fire; his ring of power is Narya, the Ring of \nFire. As such, he delights in fireworks to entertain the hobbits of the Shire, while in great \nneed he uses fire as a weapon. As one of the Maiar, he is an immortal spirit from Valinor, \nbut his physical body can be killed.\n\"\"\"\n\ngandalf\n\n'\\nGandalf is a protagonist in J. R. R. Tolkien\\'s novels The Hobbit and The Lord of the Rings. \\nHe is a wizard, one of the Istari order, and the leader of the Fellowship of the Ring. Tolkien took the \\nname \"Gandalf\" from the Old Norse \"Catalogue of Dwarves\" (Dvergatal) in the Völuspá.\\n\\nAs a wizard and the bearer of one of the Three Rings, Gandalf has great power, but works mostly by \\nencouraging and persuading. He sets out as Gandalf the Grey, possessing great knowledge and \\ntravelling continually. Gandalf is focused on the mission to counter the Dark Lord Sauron by \\ndestroying the One Ring. He is associated with fire; his ring of power is Narya, the Ring of \\nFire. As such, he delights in fireworks to entertain the hobbits of the Shire, while in great \\nneed he uses fire as a weapon. As one of the Maiar, he is an immortal spirit from Valinor, \\nbut his physical body can be killed.\\n'\n\n\nWell as is we have some work to do on the text to clean it up, as is often required. So lets do that. we need to strip special characters, quotes, and some other things.\nSteps: - use a regular expression (regex) to strip out punctuaton - convert everything to lower\n\nimport re\n\ngandalf_filtered = re.sub(r'[^\\w\\s]|\\n', '', gandalf).lower().split(' ')\nprint(gandalf_filtered)\n\n['gandalf', 'is', 'a', 'protagonist', 'in', 'j', 'r', 'r', 'tolkiens', 'novels', 'the', 'hobbit', 'and', 'the', 'lord', 'of', 'the', 'rings', 'he', 'is', 'a', 'wizard', 'one', 'of', 'the', 'istari', 'order', 'and', 'the', 'leader', 'of', 'the', 'fellowship', 'of', 'the', 'ring', 'tolkien', 'took', 'the', 'name', 'gandalf', 'from', 'the', 'old', 'norse', 'catalogue', 'of', 'dwarves', 'dvergatal', 'in', 'the', 'völuspáas', 'a', 'wizard', 'and', 'the', 'bearer', 'of', 'one', 'of', 'the', 'three', 'rings', 'gandalf', 'has', 'great', 'power', 'but', 'works', 'mostly', 'by', 'encouraging', 'and', 'persuading', 'he', 'sets', 'out', 'as', 'gandalf', 'the', 'grey', 'possessing', 'great', 'knowledge', 'and', 'travelling', 'continually', 'gandalf', 'is', 'focused', 'on', 'the', 'mission', 'to', 'counter', 'the', 'dark', 'lord', 'sauron', 'by', 'destroying', 'the', 'one', 'ring', 'he', 'is', 'associated', 'with', 'fire', 'his', 'ring', 'of', 'power', 'is', 'narya', 'the', 'ring', 'of', 'fire', 'as', 'such', 'he', 'delights', 'in', 'fireworks', 'to', 'entertain', 'the', 'hobbits', 'of', 'the', 'shire', 'while', 'in', 'great', 'need', 'he', 'uses', 'fire', 'as', 'a', 'weapon', 'as', 'one', 'of', 'the', 'maiar', 'he', 'is', 'an', 'immortal', 'spirit', 'from', 'valinor', 'but', 'his', 'physical', 'body', 'can', 'be', 'killed']\n\n\nOk, so we have this list of words. Now what? Well to get the word counts we have a few options: - Cheat and use collections.Counter - Use a for loop\nIn either case we can get our word counts into a dict, but using a dictionary comprehension isn’t super efficient because we need to do some information retrieval from the dict. An alternative is using collections.defaultdict.\n\n# method 1: collections.Counter\nfrom collections import Counter\n\ngandalf_wc_v1 = Counter(gandalf_filtered)\nprint(gandalf_wc_v1)\n\nCounter({'the': 20, 'of': 11, 'is': 6, 'he': 6, 'gandalf': 5, 'and': 5, 'a': 4, 'in': 4, 'one': 4, 'ring': 4, 'as': 4, 'great': 3, 'fire': 3, 'r': 2, 'lord': 2, 'rings': 2, 'wizard': 2, 'from': 2, 'power': 2, 'but': 2, 'by': 2, 'to': 2, 'his': 2, 'protagonist': 1, 'j': 1, 'tolkiens': 1, 'novels': 1, 'hobbit': 1, 'istari': 1, 'order': 1, 'leader': 1, 'fellowship': 1, 'tolkien': 1, 'took': 1, 'name': 1, 'old': 1, 'norse': 1, 'catalogue': 1, 'dwarves': 1, 'dvergatal': 1, 'völuspáas': 1, 'bearer': 1, 'three': 1, 'has': 1, 'works': 1, 'mostly': 1, 'encouraging': 1, 'persuading': 1, 'sets': 1, 'out': 1, 'grey': 1, 'possessing': 1, 'knowledge': 1, 'travelling': 1, 'continually': 1, 'focused': 1, 'on': 1, 'mission': 1, 'counter': 1, 'dark': 1, 'sauron': 1, 'destroying': 1, 'associated': 1, 'with': 1, 'narya': 1, 'such': 1, 'delights': 1, 'fireworks': 1, 'entertain': 1, 'hobbits': 1, 'shire': 1, 'while': 1, 'need': 1, 'uses': 1, 'weapon': 1, 'maiar': 1, 'an': 1, 'immortal': 1, 'spirit': 1, 'valinor': 1, 'physical': 1, 'body': 1, 'can': 1, 'be': 1, 'killed': 1})\n\n\n\n# method 2: for loop\n\ngandalf_wc_v2 = {}\n# Count number of times each word comes up in list of words (in dictionary)\nfor w in gandalf_filtered:\n    if w not in gandalf_wc_v2.keys():\n        gandalf_wc_v2[w] = 1\n    else:\n        gandalf_wc_v2[w] += 1\n\nprint(gandalf_wc_v2)\n\n{'gandalf': 5, 'is': 6, 'a': 4, 'protagonist': 1, 'in': 4, 'j': 1, 'r': 2, 'tolkiens': 1, 'novels': 1, 'the': 20, 'hobbit': 1, 'and': 5, 'lord': 2, 'of': 11, 'rings': 2, 'he': 6, 'wizard': 2, 'one': 4, 'istari': 1, 'order': 1, 'leader': 1, 'fellowship': 1, 'ring': 4, 'tolkien': 1, 'took': 1, 'name': 1, 'from': 2, 'old': 1, 'norse': 1, 'catalogue': 1, 'dwarves': 1, 'dvergatal': 1, 'völuspáas': 1, 'bearer': 1, 'three': 1, 'has': 1, 'great': 3, 'power': 2, 'but': 2, 'works': 1, 'mostly': 1, 'by': 2, 'encouraging': 1, 'persuading': 1, 'sets': 1, 'out': 1, 'as': 4, 'grey': 1, 'possessing': 1, 'knowledge': 1, 'travelling': 1, 'continually': 1, 'focused': 1, 'on': 1, 'mission': 1, 'to': 2, 'counter': 1, 'dark': 1, 'sauron': 1, 'destroying': 1, 'associated': 1, 'with': 1, 'fire': 3, 'his': 2, 'narya': 1, 'such': 1, 'delights': 1, 'fireworks': 1, 'entertain': 1, 'hobbits': 1, 'shire': 1, 'while': 1, 'need': 1, 'uses': 1, 'weapon': 1, 'maiar': 1, 'an': 1, 'immortal': 1, 'spirit': 1, 'valinor': 1, 'physical': 1, 'body': 1, 'can': 1, 'be': 1, 'killed': 1}\n\n\nI will use either method, but tend to prefer writing less code that I have to maintain. If there is a helper class or function that is in a stable release of a library, it makes life easier to use it.\nBecause it doesn’t matter much which one we use for our example, we’ll just grab gandalf_wc_v2 and get the top N values that exceed a certain word length. There are a ton of ways to do this, we will just use plain python.\n\nWe could have done this in one more line on our collections.Counter method call like this: gandalf_wc_v1.most_common(n=5)\n\nBut that is too easy, so let’s do it longhand:\n\n# key value pairs where key is >= 3\ngandalf_wl_geq_3 = {k:v for k,v in gandalf_wc_v2.items() if len(k) >= 3}\n# top N counts\nn = 5\ntop_n = sorted(gandalf_wl_geq_3.values(), reverse=True)[:n]\n#[20, 5, 5, 4, 4]\n\n# finally, a fun use of a dict comp:\n{k:v for k,v in gandalf_wl_geq_3.items() if v in top_n}\n\n{'gandalf': 5, 'the': 20, 'and': 5, 'one': 4, 'ring': 4}\n\n\nLast but perhaps one of the best, comprehensions on Pandas Dataframe columns\nlets create a dataframe with some sample data. To make it interesting I’ll use some comprehensions and other native python capabilities to create a dataset for this example, instead of using Iris or Housing.\n\nimport pandas as pd\nimport numpy as np\nfrom itertools import combinations\n\nyrs = range(2018,2022,1)\ncities = 'Bozeman, MT', 'Spokane, WA', 'Bangor, ME', 'White Plains, NY', 'Sedona, AZ'\ncat1 = ['wizard', 'ranger', 'elf', 'hutt', 'orc', 'nazgul', 'numenorean', 'deciever']\n\ncolnames = 'year','city','role','points'\nds = [[y,c,k, np.random.randint(-10, 10)] for k in cat1 for c in cities for y in yrs]\n\ndf = pd.DataFrame(ds, columns=colnames)\ndisplay(df.head(3), df.shape)\n\n\n\n\n\n  \n    \n      \n      year\n      city\n      role\n      points\n    \n  \n  \n    \n      0\n      2018\n      Bozeman, MT\n      wizard\n      3\n    \n    \n      1\n      2019\n      Bozeman, MT\n      wizard\n      -9\n    \n    \n      2\n      2020\n      Bozeman, MT\n      wizard\n      -8\n    \n  \n\n\n\n\n(160, 4)\n\n\nSo we have some meaningless data. Now lets group by to get a multiindex that we want to manipulate, the whole point of this little exercise.\n\ndfg = df.groupby(by=['city', 'role']).agg({'points': ['mean','sum', np.std]}).reset_index()\ndfg.head(3)\n\n\n\n\n\n  \n    \n      \n      city\n      role\n      points\n    \n    \n      \n      \n      \n      mean\n      sum\n      std\n    \n  \n  \n    \n      0\n      Bangor, ME\n      deciever\n      4.50\n      18\n      3.872983\n    \n    \n      1\n      Bangor, ME\n      elf\n      0.75\n      3\n      7.889867\n    \n    \n      2\n      Bangor, ME\n      hutt\n      -1.25\n      -5\n      5.560276\n    \n  \n\n\n\n\nSo this isn’t super useful for anything. Now normally some dataset for machine learning or what not will have a much broader set of columns (a.k.a. features), but the concept is pretty much the same. Just remember to work on manageable chunks and don’t get intimidated by a long chain of transformations.\n\nprint(f'Initial column list: {dfg.columns}')\n\nInitial column list: MultiIndex([(  'city',     ''),\n            (  'role',     ''),\n            ('points', 'mean'),\n            ('points',  'sum'),\n            ('points',  'std')],\n           )\n\n\nSo first I’ll demonstrate updating this with a list comprehension. This is a bit more complex of a list comprehension in that in incorporates a conditional ''.join in the output. Basically what is happening is we are looking at each tuple in the multiindex, and if the last item is an empty string, we underscore join all but the lst element, otherwise we join the whole thing.\n\ndfg_copy1 = dfg.copy()\ndfg_copy1.columns = ['_'.join(list(x) if len(x[-1]) > 0 else x[:-1]) for x in dfg_copy1.columns]\ndfg_copy1.head(2)\n\n\n\n\n\n  \n    \n      \n      city\n      role\n      points_mean\n      points_sum\n      points_std\n    \n  \n  \n    \n      0\n      Bangor, ME\n      deciever\n      4.50\n      18\n      3.872983\n    \n    \n      1\n      Bangor, ME\n      elf\n      0.75\n      3\n      7.889867\n    \n  \n\n\n\n\nThere is another way, however, that is pretty clever. It is more of a functional style and I’m fairly certain I’ve seen it used in the Fast AI course or notebooks in addition to numerous tutorials on the internet. We will be using the map function over our columns.\n\ndfg_copy2 = dfg.copy()\ndfg_copy2.columns = dfg_copy2.columns.map(lambda x : '_'.join(x) if x[-1] != '' else x[0]))\n\ndfg_copy2.head(3)\n\n\n\n\n\n  \n    \n      \n      city\n      role\n      points\n      points\n      points\n    \n  \n  \n    \n      0\n      Bangor, ME\n      deciever\n      4.50\n      18\n      3.872983\n    \n    \n      1\n      Bangor, ME\n      elf\n      0.75\n      3\n      7.889867\n    \n    \n      2\n      Bangor, ME\n      hutt\n      -1.25\n      -5\n      5.560276\n    \n  \n\n\n\n\nWhile this is really quick and easy if there isn’t any weird conditions (e.g. you can just use {dataframe_name}.columns.map('_'.join)), above we only have the multiindex on some columns, so handling the city and role columns differently is something useful to do for readbility. So there you have it, a bonus method of map + lambda to achieve the same goal as a list comprehension.\n\nWell for now that is plenty of information. Hopefully this helps a future task of yours regardless of your proficiency in technical terminonology."
  },
  {
    "objectID": "posts/dl-basics-with-fastai/index.html",
    "href": "posts/dl-basics-with-fastai/index.html",
    "title": "Fastai Course v2022, Lessons 1 and 2",
    "section": "",
    "text": "Recently I started the Fast.ai course Practical Deep Learning For Coders. Now this isn’t my first time around but I feel less intimidated this time. I watched all the video lessons for the 2020 version of the course, gaining some high level knowledge. I bought the book as well, which is mentioned on the course site lined above. I was excited about what is possible in deep learning yet equally intimidated by the sheer scope of the field.\nTo this day I am a believer in impostor syndrome; that is, I am living it on daily basis. Though I feel like I don’t know anything I am making tremendous progress in areas directly and indirectly related to deep learning.\nFor the 2020 course I found it hard to go beyond just running the provided notebooks. The barrier for me - and I’d wager for many others - is getting overwhelmed and making a list of things to learn instead of just doing it. This runs contrary to the Fast.ai principle of top down learning. For me there is a fear of failure in learning and/or establishing a career in data sience.\nYet everyone starts from somewhere and I don’t believe its possible to go from zero to hero in a few weeks. Consistent effort is the recipe for success. Some people find success more quickly, others it takes longer. Persistence is key.\nAs noted in my first blog post, I’ve resisted starting a blog even though it is an excellent way to share and learn. As I learn I hope to share perspectives that are suited towards people like me; those that are always learning and like to relate to things common sense terms. Lets get started!\n\n\nWhat is deep learning and what is it all about?*\n\nIn normal human speak, deep learning is an evolution and subset of machine learning.\nDeep Learning (DL) is centered around something called neural networks.\nNeural nets are a type of machine learning model architecture, which in theory permit a universally flexible function to approximate any relationship of observations to outcomes.\nA machine learning model is a general way to solve a problem. For example, given some data and some label that it belongs to, e.g. demographic data (features) that maps to what your income might be (target), we try to create a model which “learns” how X (features) maps to y (target).\nA model architecture is the math behind this process. Neural nets are flexible because they use clever math to create and learn values of hidden parameters that allow us to go from X -> y.\nDo you need to know the details beyond this? Yeah, you do. But not yet. Don’t worry about it!\n\nCan deep learning be easy?\n\nJeremy Howard says it can be learned by doing, and some things that were beyond difficult a decade ago are trivial today.\nIt is not easy, however, nor is it quick to learn. Practice on a regular basis and you will accumilate knowledge.\n\nWhat is a simple way to train a model?\nFirst of all, do yourself a favor and don’t try to write things from scratch. Use Fastai or another library which can abstract the details and boilerplate code. Second, create a model! This will be a computer vision model that classifies species of houseplants. Pick some topic that interests you and solve a trivial problem.\n\nHere is the repo behind this app, hosted on huggingface spaces here\nSteps:\n\nget data: web scrape from duck duck go\npreprocess data\ntrain model\nevaulate result\ncreate a Gradio app: you don’t need to do much!\npublish model to Huggingface Spaces: use git or even the file upload if git sounds too hard right now\n\n\n\n\n\n\n\n\n\n\nCreating a project like the above is relatively straightfoward, but I totally understand how it can seem hard at first. Getting an error or trying to figure out how something works can be a tedious process, but you can do it. It is challenging to learn, and easy to get discouraged. But everyone starts somewhere, and you learn by doing. Stay positive and patient!"
  },
  {
    "objectID": "posts/thoughts-on-llms-jan-2023/index.html",
    "href": "posts/thoughts-on-llms-jan-2023/index.html",
    "title": "How I feel about generative models like ChatGPT: Jan 2023",
    "section": "",
    "text": "There has been a lot of buzz lately around certain generative models like ChatGPT, Codex, Dall-e 2, Bert, Stable Diffusion, and others. What they seem to have in common is:\n\nThey were trained on massive datasets\nThey are “large” models in that they have hundreds of millions or even many billions of learned parameters\nThey were made by super smart people with access to state of the art GPU clusters\nThey cost a lot of money to train\n\nThis seems to be at odds with the majority of the data science community, practitioners with far less resources, knowledge, and capabilities. In a way it’s a have and have-nots situation. But then again what have these models accomplished? Sure, there is novelty, some fun, and a ton of potential. However there is growing awareness and fear of AI and I feel like this has sparked calls for regulation, transparency, and improved data ethics.\nIf you aren’t working for companies like OpenAI, Stability AI, Microsoft, or Google, there are still options for you. First, don’t get discouraged by the hype. If anything, embrace it. We are already seeing open sourcing of big models like BLOOM and Stable Diffusion, which brings large scale transfer learning in reach. Specifically if we look at TIMM or HuggingFace we see a ton of pretrained models that are supported by a robust community of brilliant folks with a passion for open source. These might not be the hyped models like ChatGPT, but we can still build amazing things with other model architectures.\nI think what is more important is to take advantage of the options provided by HuggingFace and others, the ability to test out pre-trained models and see how they go in your use case, on low-cost or free GPUs at a small scale. That is how everything starts, from an interesting idea, proof of concept, or passion. Start small, be happy you are living in an age of rapid AI development and community sharing, and focus on problems that you are about or that are beneficial to your situation.\n\n\nHonestly I cannot say. The best defense anyone has against being replaced or reduced to redundancy is to continue learning, exploring, and innovating. If aren’t creating new model architectures and are working as a data scientist or similar, you can still leverage these new technologies to create value for your company. The models themselves are really cool, but what is most important is business viability. Whether that means creating a company around an idea, or bringing new ideas to your company, the key is to keep looking for solutions to real life problems.\nI am hesistant to take a stance on this but I will say that I have some anxiety around whether I have a future in data science. It’s all about perspective and finding a place for yourself. Take AutoML for classical ML problems. It is pretty cool in that you can efficiently test out many model architectures and hyperparameter spaces without having to write hundreds of lines of code with the scikit-learn api. But, it also automates much of what we are taught in a machine learning course.\nAs a reminder to myself and others I’ll leave you with this thought: Don’t be discouraged by the progress in research. Embrace it and know that your knowledge so far will help you better leverage these tools than those without a background in data science. Just because something new comes out that is a game changer, doesn’t mean its going to replace you. Last, take advantage of tools which permit you to write less boilerplate code and focus on the problem at hand."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "On this page I’ll be posting links to projects I’ve worked on and/or research I’ve contributed to.\n\n\n\n\n\n\n   \n     \n     \n       Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Yarri Bryn",
    "section": "",
    "text": "Hi, I’m Yarri,\n\nThe cute one is Mateo - aka Mr. Dude - the toddler who is a bundle of chaos at present.\n\nI am a Data Scientist at Wipfli LLP, and this site is for blogging, sharing how-to’s, and sharing a little bit about me.\nFor 2023 I’ve set a goal to begin blogging, mostly because I’m apprehensive to do so. I’ll be focusing on blogging and posting how-to’s, but I hope to add shareable content that few people will see or subscribe to 😂"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Yarri",
    "section": "",
    "text": "Yarri Bryn is a Data Scientist at Wipfli LLP. Yarri is married with one kiddo, Mateo, whom he hopes will grow up to be curious. He also likes golf, spending time outdoors, and various athletic and non-athletic hobbies.\n\n\nUniversity of Wisconsin - Eau Claire | Eau Claire, WI M.S. in Data Science | Sept 2019 - May 2022\nUniversity of Northern Iowa | Cedar Falls, Iowa B.A. in Marketing Management | Sept 2009 - May 2013\n\n\n\nWipfli LLP | Data Scientist / Data Engineer | January 2022-Present\nMinneapolis Park and Recreation Board | Parking & Business Systems Professional | February 2015 - Jan 2022\nSelf-Employed | Professional Golfer | September 2013 - October 2017\n\n\n  \n  \n  \n    \n     LinkedIn\n  \n  \n    \n     Github\n  \n  \n     Kaggle"
  },
  {
    "objectID": "about.html#certifications",
    "href": "about.html#certifications",
    "title": "About Yarri",
    "section": "Certifications",
    "text": "Certifications"
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About Yarri",
    "section": "Skills",
    "text": "Skills\n\nSoft Skills\n\nCommunication\nCollaboration\nProblem Solving\n\nTechnical Skills\n\nData Engineering\nMachine Learning\nDevOps/MLOps\nInfrastructure as Code\n\nTools\n\nMicrosoft: Azure Synapse Analytics (and ADF), AzureML, SQL Server, PowerBI\nOpen Source: Git, Shell (bash/zsh), Anaconda, Docker\nOther: Terraform\n\nLanguages\n\nPython\nSQL\nSpark/PySpark"
  },
  {
    "objectID": "howto.html",
    "href": "howto.html",
    "title": "My TILs (Today I Learned)",
    "section": "",
    "text": "Date\n\n\nTitle\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Below are my most recent blog posts on a variety of topics, ordered by date.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow I feel about generative models like ChatGPT: Jan 2023\n\n\n\n\n\n\n\ndeep learning\n\n\ngenerative models\n\n\nlarge language models\n\n\n\n\nThe good and the anxiety inducing\n\n\n\n\n\n\nJan 18, 2023\n\n\nYarri Bryn\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat an MS in Data Science gets you\n\n\n\n\n\n\n\neducation\n\n\ndata science\n\n\n\n\nSpoiler: it depends on your background\n\n\n\n\n\n\nJan 16, 2023\n\n\nYarri Bryn\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFastai Course v2022, Lessons 1 and 2\n\n\n\n\n\n\n\nabout\n\n\nfastai\n\n\ndeep learning\n\n\n\n\nDeep Learning in normal human speak + A sample app\n\n\n\n\n\n\nJan 5, 2023\n\n\nYarri Bryn\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhy would I blog?\n\n\n\n\n\n\n\nnews\n\n\ngeneral\n\n\npython\n\n\ncomprehensions\n\n\n\n\nIt is mostly a personal goal, but if anyone reads this I hope it is informative\n\n\n\n\n\n\nJan 1, 2023\n\n\nYarri Bryn\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  }
]